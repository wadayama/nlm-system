#!/usr/bin/env python
"""Test performance impact of variable operations with gpt-5"""

from time import time
from nlm_interpreter import NLMSession


def test_gpt5_performance():
    """Compare performance with and without variables using gpt-5"""
    print("="*70)
    print("ğŸ” gpt-5 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆå¤‰æ•°æ“ä½œã®å½±éŸ¿ï¼‰")
    print("="*70)
    
    session = NLMSession(model="gpt-5", namespace="gpt5_perf_test")
    
    # Test 1: No variables (just text processing)
    print("\n1ï¸âƒ£ å¤‰æ•°ãªã—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã®ã¿ï¼‰:")
    print("-" * 50)
    
    no_var_commands = [
        "Tell me what is 2+2",
        "Say hello world",
        "Count from 1 to 5",
        "What day comes after Monday?"
    ]
    
    no_var_times = []
    for cmd in no_var_commands:
        print(f"\nCommand: {cmd}")
        start = time()
        try:
            result = session.execute(cmd)
            elapsed = time() - start
            no_var_times.append(elapsed)
            print(f"  â±ï¸  Time: {elapsed:.3f}s")
            print(f"  Result: {result[:80]}...")
        except Exception as e:
            print(f"  âŒ Error: {e}")
    
    # Test 2: With variable save operations
    print("\n\n2ï¸âƒ£ å¤‰æ•°ä¿å­˜ã‚ã‚Š ({{variable}}):")
    print("-" * 50)
    
    var_commands = [
        "Set {{answer}} to the result of 2+2",
        "Store 'hello world' in {{greeting}}",
        "Save the count from 1 to 5 in {{numbers}}",
        "Put 'Tuesday' in {{next_day}}"
    ]
    
    var_times = []
    for cmd in var_commands:
        print(f"\nCommand: {cmd}")
        start = time()
        try:
            result = session.execute(cmd)
            elapsed = time() - start
            var_times.append(elapsed)
            print(f"  â±ï¸  Time: {elapsed:.3f}s")
            
            # Extract variable name and show value
            if "{{" in cmd:
                var_name = cmd[cmd.find("{{")+2:cmd.find("}}")]
                value = session.get(var_name)
                print(f"  Variable: {var_name} = {value}")
        except Exception as e:
            print(f"  âŒ Error: {e}")
    
    # Test 3: Variable read operations
    print("\n\n3ï¸âƒ£ å¤‰æ•°èª­ã¿å–ã‚Šã‚ã‚Š:")
    print("-" * 50)
    
    # First set some variables
    session.save("test_value", "42")
    session.save("test_name", "Alice")
    
    read_commands = [
        "What is the value of {{test_value}}?",
        "Tell me about {{test_name}}",
        "Combine {{test_value}} and {{test_name}} into a sentence"
    ]
    
    read_times = []
    for cmd in read_commands:
        print(f"\nCommand: {cmd}")
        start = time()
        try:
            result = session.execute(cmd)
            elapsed = time() - start
            read_times.append(elapsed)
            print(f"  â±ï¸  Time: {elapsed:.3f}s")
            print(f"  Result: {result[:80]}...")
        except Exception as e:
            print(f"  âŒ Error: {e}")
    
    # Summary and Comparison
    print("\n\n" + "="*70)
    print("ğŸ“Š gpt-5 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:")
    print("="*70)
    
    if no_var_times:
        avg_no_var = sum(no_var_times) / len(no_var_times)
        print(f"\n1ï¸âƒ£ å¤‰æ•°ãªã—:")
        print(f"   å¹³å‡: {avg_no_var:.3f}s")
        print(f"   æœ€é€Ÿ: {min(no_var_times):.3f}s")
        print(f"   æœ€é…: {max(no_var_times):.3f}s")
    
    if var_times:
        avg_var = sum(var_times) / len(var_times)
        print(f"\n2ï¸âƒ£ å¤‰æ•°ä¿å­˜:")
        print(f"   å¹³å‡: {avg_var:.3f}s")
        print(f"   æœ€é€Ÿ: {min(var_times):.3f}s")
        print(f"   æœ€é…: {max(var_times):.3f}s")
    
    if read_times:
        avg_read = sum(read_times) / len(read_times)
        print(f"\n3ï¸âƒ£ å¤‰æ•°èª­ã¿å–ã‚Š:")
        print(f"   å¹³å‡: {avg_read:.3f}s")
        print(f"   æœ€é€Ÿ: {min(read_times):.3f}s")
        print(f"   æœ€é…: {max(read_times):.3f}s")
    
    # Performance impact analysis
    if no_var_times and var_times:
        impact = (avg_var - avg_no_var) / avg_no_var * 100
        print(f"\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿:")
        print(f"   å¤‰æ•°ä¿å­˜ã¯ {impact:.0f}% é…ã„")
        
        if impact > 100:
            print(f"   ğŸ”´ å¤§å¹…ãªã‚¹ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒåŸå› ")
        elif impact > 50:
            print(f"   ğŸŸ¡ é¡•è‘—ãªã‚¹ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å‡¦ç†ã®å½±éŸ¿")
        else:
            print(f"   ğŸŸ¢ å½±éŸ¿ã¯è»½å¾®")
    
    # Compare with all models
    print("\n\nğŸ“ˆ å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ:")
    print("-" * 50)
    print("| ãƒ¢ãƒ‡ãƒ«      | å¤‰æ•°ãªã— | å¤‰æ•°ä¿å­˜ | å¤‰æ•°èª­å– |")
    print("|------------|---------|---------|---------|")
    print("| gpt-5-nano | 3.3ç§’   | 10.6ç§’  | 8.7ç§’   |")
    print("| gpt-5-mini | 3.4ç§’   | 5.5ç§’   | 6.9ç§’   |")
    
    if no_var_times and var_times:
        read_avg_str = f"{avg_read:.1f}ç§’" if read_times else "N/A"
        print(f"| gpt-5      | {avg_no_var:.1f}ç§’   | {avg_var:.1f}ç§’   | {read_avg_str}   |")
        
        print(f"\nğŸ† ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
        # Determine best model for each category
        models_no_var = [("gpt-5-nano", 3.3), ("gpt-5-mini", 3.4), ("gpt-5", avg_no_var)]
        models_var = [("gpt-5-nano", 10.6), ("gpt-5-mini", 5.5), ("gpt-5", avg_var)]
        
        models_no_var.sort(key=lambda x: x[1])
        models_var.sort(key=lambda x: x[1])
        
        print(f"\n  å¤‰æ•°ãªã—å‡¦ç†ï¼ˆé€Ÿã„é †ï¼‰:")
        for i, (model, t) in enumerate(models_no_var, 1):
            medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
            print(f"    {medal} {model}: {t:.1f}ç§’")
        
        print(f"\n  å¤‰æ•°ä¿å­˜å‡¦ç†ï¼ˆé€Ÿã„é †ï¼‰:")
        for i, (model, t) in enumerate(models_var, 1):
            medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
            print(f"    {medal} {model}: {t:.1f}ç§’")


if __name__ == "__main__":
    try:
        test_gpt5_performance()
    except KeyboardInterrupt:
        print("\nâš ï¸ Test interrupted")
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()