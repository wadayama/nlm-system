#!/usr/bin/env python
"""Test if max_tokens is needed for gpt-oss:20b"""

from nlm_interpreter import NLMSession


def test_without_max_tokens():
    """Test gpt-oss:20b without max_tokens parameter"""
    print("="*60)
    print("gpt-oss:20b max_tokens ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ")
    print("="*60)
    
    # Test with current implementation (max_tokens included)
    print("\n1ï¸âƒ£ ç¾åœ¨ã®å®Ÿè£…ï¼ˆmax_tokens=1000ã‚ã‚Šï¼‰:")
    try:
        session = NLMSession(model="gpt-oss:20b", namespace="test_max_tokens")
        result = session.execute("Set {{test1}} to 'With max_tokens'")
        value = session.get("test1")
        print(f"   âœ… æˆåŠŸ: {value}")
        print(f"   Result length: {len(result)} characters")
    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n2ï¸âƒ£ max_tokensãªã—ã®ãƒ†ã‚¹ãƒˆ:")
    print("   ä¸€æ™‚çš„ã«max_tokensã‚’å‰Šé™¤ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™...")
    
    # Temporarily test without max_tokens
    from nlm_interpreter import NLMSession
    import json
    from openai import OpenAI
    
    # Create a test session
    test_session = NLMSession(model="gpt-oss:20b", namespace="test_no_max")
    
    # Test direct API call without max_tokens
    try:
        client = OpenAI(
            base_url="http://localhost:1234/v1",
            api_key="not-needed"
        )
        
        response = client.chat.completions.create(
            model="gpt-oss:20b",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Say 'Hello World' and nothing else."}
            ]
            # No max_tokens parameter
        )
        
        content = response.choices[0].message.content
        print(f"   âœ… max_tokensãªã—ã§ã‚‚å‹•ä½œ!")
        print(f"   Response: {content}")
        print(f"   Response length: {len(content)} characters")
        
    except Exception as e:
        print(f"   âŒ max_tokensãªã—ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n3ï¸âƒ£ é•·ã„å‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆï¼ˆmax_tokensãªã—ï¼‰:")
    try:
        response = client.chat.completions.create(
            model="gpt-oss:20b",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Count from 1 to 100."}
            ]
            # No max_tokens parameter
        )
        
        content = response.choices[0].message.content
        print(f"   âœ… é•·ã„å‡ºåŠ›ã‚‚æˆåŠŸ!")
        print(f"   Response length: {len(content)} characters")
        print(f"   First 100 chars: {content[:100]}...")
        
    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n" + "="*60)
    print("ğŸ“Š çµè«–:")
    print("="*60)
    print("max_tokensãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ï¼š")
    print("- gpt-oss:20bï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãªãã¦ã‚‚å‹•ä½œï¼‰")
    print("- gpt-5ã‚·ãƒªãƒ¼ã‚ºï¼ˆOpenAIï¼‰: ä½¿ç”¨ä¸å¯ï¼ˆã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ï¼‰")
    print("\nğŸ’¡ æ¨å¥¨: max_tokensãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®Œå…¨ã«å‰Šé™¤")


if __name__ == "__main__":
    try:
        test_without_max_tokens()
    except KeyboardInterrupt:
        print("\nâš ï¸ Test interrupted")
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()