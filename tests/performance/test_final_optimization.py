#!/usr/bin/env python
"""Test final optimization with both reasoning_effort='low' and verbosity='low'"""

import time
from nlm_interpreter import NLMSession
import statistics


def test_final_optimization():
    """Test combined reasoning_effort='low' and verbosity='low'"""
    print("="*70)
    print("ğŸš€ æœ€çµ‚æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
    print("reasoning_effort='low' + verbosity='low'")
    print("="*70)
    
    session = NLMSession(model="gpt-5-nano", namespace="final_opt_test")
    
    # Comprehensive test cases
    test_cases = [
        ("Basic assignment", "Set {{name}} to 'Bob'"),
        ("Math calculation", "Calculate 18 * 25 and save to {{math}}"),
        ("Multi-variable", "Set {{x}} to 10 and {{y}} to 20"),
        ("Japanese", "{{å ´æ‰€}}ã‚’'éŠ€åº§'ã«è¨­å®šã—ã¦ãã ã•ã„"),
        ("Complex calc", "Calculate (15 + 5) * 3 and store in {{result}}"),
        ("String processing", "Save 'Final Test' to {{message}}"),
        ("No variable", "What is 6 + 4?"),
        ("Conditional", "If 8 > 5, set {{status}} to 'pass'")
    ]
    
    print(f"\nğŸ“Š æœ€çµ‚æœ€é©åŒ–å¾Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š:")
    print("-" * 50)
    
    times = []
    var_times = []
    no_var_times = []
    successful_tests = 0
    
    for i, (test_name, command) in enumerate(test_cases, 1):
        print(f"\n{i}. {test_name}:")
        print(f"   Command: {command}")
        
        start = time.time()
        try:
            result = session.execute(command)
            elapsed = time.time() - start
            times.append(elapsed)
            
            # Categorize times
            if "{{" in command:
                var_times.append(elapsed)
            else:
                no_var_times.append(elapsed)
            
            print(f"   â±ï¸  Time: {elapsed:.3f}s")
            
            # Verify result
            if "{{" in command and "}}" in command:
                var_name = command[command.find("{{")+2:command.find("}}")]
                value = session.get(var_name)
                if value:
                    print(f"   âœ… Variable: {var_name} = '{value}'")
                    successful_tests += 1
                else:
                    print(f"   âŒ Variable not set properly")
            else:
                print(f"   ğŸ“ Response: {result[:80]}...")
                if result and len(result) > 0:
                    successful_tests += 1
            
            # Show response length for verbosity analysis
            print(f"   ğŸ“ Response length: {len(result)} chars")
                
        except Exception as e:
            print(f"   âŒ Error: {e}")
    
    # Performance analysis
    if times:
        print("\n" + "="*70)
        print("ğŸ“ˆ æœ€çµ‚æœ€é©åŒ–çµæœ:")
        print("="*70)
        
        avg_time = statistics.mean(times)
        success_rate = (successful_tests / len(test_cases)) * 100
        
        print(f"  ãƒ†ã‚¹ãƒˆæˆåŠŸç‡: {successful_tests}/{len(test_cases)} ({success_rate:.1f}%)")
        print(f"  å¹³å‡å®Ÿè¡Œæ™‚é–“: {avg_time:.3f}s")
        print(f"  æœ€é€Ÿ: {min(times):.3f}s")
        print(f"  æœ€é…: {max(times):.3f}s")
        print(f"  ä¸­å¤®å€¤: {statistics.median(times):.3f}s")
        
        if var_times:
            print(f"\n  å¤‰æ•°ã‚ã‚Šæ“ä½œ:")
            print(f"    å¹³å‡: {statistics.mean(var_times):.3f}s")
            print(f"    æœ€é€Ÿ: {min(var_times):.3f}s")
            print(f"    æœ€é…: {max(var_times):.3f}s")
        
        if no_var_times:
            print(f"\n  å¤‰æ•°ãªã—æ“ä½œ:")
            print(f"    å¹³å‡: {statistics.mean(no_var_times):.3f}s")
        
        # Historical comparison
        print("\n" + "="*70)
        print("ğŸ“Š å…¨è¨­å®šæ¯”è¼ƒ (æœ€çµ‚):")
        print("="*70)
        
        configurations = [
            ("Original (ãªã—)", 11.3, 100),
            ("reasoning_effort='minimal'", 2.0, 12),
            ("reasoning_effort='low'", 5.5, 100),
            ("æœ€çµ‚æœ€é©åŒ– (low+verbosity)", avg_time, success_rate)
        ]
        
        print(f"{'è¨­å®š':<25} {'æ™‚é–“':<8} {'å“è³ª':<8} {'è©•ä¾¡'}")
        print("-" * 60)
        
        for config_name, time_val, quality_val in configurations:
            if time_val < 3:
                time_rating = "ğŸš€"
            elif time_val < 6:
                time_rating = "âœ…"
            elif time_val < 10:
                time_rating = "âš ï¸"
            else:
                time_rating = "ğŸ¢"
            
            if quality_val >= 95:
                quality_rating = "ğŸ¯"
            elif quality_val >= 80:
                quality_rating = "âœ…"
            elif quality_val >= 50:
                quality_rating = "âš ï¸"
            else:
                quality_rating = "âŒ"
            
            print(f"{config_name:<25} {time_val:<8.1f}s {quality_val:<8.0f}% {time_rating}{quality_rating}")
        
        # Calculate total improvement
        baseline_time = 11.3
        improvement = (baseline_time - avg_time) / baseline_time * 100
        
        print(f"\nğŸ‰ æœ€çµ‚æ”¹å–„çµæœ:")
        print(f"   æ™‚é–“: {baseline_time:.1f}ç§’ â†’ {avg_time:.1f}ç§’")
        print(f"   æ”¹å–„: {improvement:.1f}% é«˜é€ŸåŒ–")
        
        if success_rate >= 95 and avg_time < 4:
            print(f"\nğŸ† æœ€é©åŒ–æˆåŠŸï¼")
            print(f"   é«˜ã„å“è³ªã¨å„ªç§€ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ä¸¡ç«‹")
            print(f"   æœ¬ç•ªç’°å¢ƒã§ã®ä½¿ç”¨ã‚’å¼·ãæ¨å¥¨")
        elif success_rate >= 80 and avg_time < 6:
            print(f"\nâœ… è‰¯å¥½ãªæœ€é©åŒ–")
            print(f"   å®Ÿç”¨çš„ãªãƒ¬ãƒ™ãƒ«ã‚’é”æˆ")
        else:
            print(f"\nâš ï¸ æ›´ãªã‚‹èª¿æ•´ãŒå¿…è¦")
        
        # Verbosity impact analysis
        baseline_response_length = 385  # From previous test
        print(f"\nğŸ’¬ verbosity='low'ã®åŠ¹æœ:")
        print(f"   å¿œç­”ã®ç°¡æ½”åŒ–ã«ã‚ˆã‚Šè¿½åŠ ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾")
        print(f"   æœŸå¾…: ã‚ˆã‚ŠçŸ­ã„å¿œç­”ã¨ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›")


if __name__ == "__main__":
    try:
        test_final_optimization()
    except KeyboardInterrupt:
        print("\nâš ï¸ Test interrupted")
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()