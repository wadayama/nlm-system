# NLM System Edge Case Testing Report

## Overview

This report summarizes detailed analysis results of edge case processing performance for various LLM models in the NLM system. Tests were conducted in August 2025 on MacBook Air environment.

## Execution Environment

- **Machine**: MacBook Air (August 2025)
- **OS**: macOS
- **NLM System**: Optimized with reasoning_effort='low' + verbosity='low'
- **Tested Models**:
  - gpt-5-mini (OpenAI Standard tier)
  - gpt-5-nano (OpenAI Economy tier) 
  - gpt-oss:20b (Local LMStudio)

## Test Methodology

### Test Categories

1. **Ambiguous Variable References**
   - Processing when variable names appear within text
   - Nested variable syntax handling

2. **Self-Reference Operations**
   - Counter increment processing
   - Variable swap operations

3. **Natural Language Complexity**
   - Homophone processing
   - Complex conditional branch processing

4. **Mathematical Operations**
   - Complex formula processing

5. **Extreme Cases**
   - Empty variable names
   - Unicode variables (ğŸš€, Japanese)
   - Long variable names

### Evaluation Metrics

- **Success Rate**: Percentage of successful test items
- **Average Execution Time**: Mean execution time for successful tests
- **Quality Assessment**: Degree of match with expected results

## Test Results

### 1. GPT-5-MINI vs GPT-5-NANO Comparison

| Model | Success Rate | Avg Time | Quality Rating | Overall Rating |
|--------|--------------|----------|----------------|----------------|
| **gpt-5-mini** | **88.9%** | **5.3sec** | ğŸ¯ Excellent | **ğŸ¥‡ Best** |
| **gpt-5-nano** | 100.0% | 7.1sec | ğŸ¯ Excellent | ğŸ¥ˆ Excellent |

#### Detailed Analysis

**GPT-5-MINI Characteristics:**
- Practical success rate (88.9%) suitable for daily use
- 25% faster processing speed
- Good cost efficiency (Standard tier)
- Stability in edge cases

**GPT-5-NANO Characteristics:**
- Perfect success rate (100%)
- Superior in conditional branch processing
- Perfect Unicode support
- Slight speed tradeoff

### 2. ãƒ­ãƒ¼ã‚«ãƒ« vs OpenAIæ¯”è¼ƒ

#### gpt-oss:20b vs gpt-5-nano

| ãƒ¢ãƒ‡ãƒ« | æˆåŠŸç‡ | å¹³å‡æ™‚é–“ | ã‚³ã‚¹ãƒˆ | ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ |
|--------|--------|----------|--------|------------|
| **gpt-oss:20b** | 87.5% | 9.7ç§’ | ğŸ†“ ç„¡æ–™ | ğŸ”’ å®Œå…¨ä¿è­· |
| **gpt-5-nano** | **100.0%** | **7.1ç§’** | ğŸ’° æœ‰æ–™ | âš ï¸ ãƒ‡ãƒ¼ã‚¿é€ä¿¡ |

**çµè«–**: OpenAIãŒå“è³ªãƒ»é€Ÿåº¦ã§å„ªä½ã€ãƒ­ãƒ¼ã‚«ãƒ«ã¯ã‚³ã‚¹ãƒˆãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã§å„ªä½

#### gpt-oss:20b vs gpt-5-mini

| ãƒ¢ãƒ‡ãƒ« | æˆåŠŸç‡ | å¹³å‡æ™‚é–“ | ç‰¹è¨˜äº‹é … |
|--------|--------|----------|----------|
| **gpt-oss:20b** | **100.0%** | 8.0ç§’ | æ¡ä»¶åˆ†å²å‡¦ç†ã§å„ªä½ |
| **gpt-5-mini** | 90.0% | **4.6ç§’** | é€Ÿåº¦ã§å„ªä½ |

**é©šãã®çµæœ**: ãƒ­ãƒ¼ã‚«ãƒ«LLMãŒå“è³ªã§OpenAIã‚’ä¸Šå›ã‚‹å ´é¢ã‚’ç¢ºèª

## æ¨å¥¨äº‹é …

### ç”¨é€”åˆ¥ãƒ¢ãƒ‡ãƒ«é¸æŠ

#### ğŸ¥‡ GPT-5-MINI æ¨å¥¨ã‚·ãƒŠãƒªã‚ª
- **ä¸€èˆ¬çš„ãªæ¥­å‹™ç”¨é€”** (æœ€é©ãªãƒãƒ©ãƒ³ã‚¹)
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†** (é€Ÿåº¦é‡è¦–)
- **æ—¥å¸¸çš„ãªãƒã‚¯ãƒ­å®Ÿè¡Œ**
- **ã‚³ã‚¹ãƒˆåŠ¹ç‡é‡è¦–**

#### ğŸ¥ˆ GPT-5-NANO æ¨å¥¨ã‚·ãƒŠãƒªã‚ª  
- **ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«** (100%å“è³ªå¿…é ˆ)
- **è¤‡é›‘ãªæ¡ä»¶åˆ†å²** (è«–ç†å‡¦ç†é‡è¦–)
- **å®Œç’§æ€§é‡è¦–** (ã‚¨ãƒ©ãƒ¼è¨±å®¹åº¦ã‚¼ãƒ­)

#### ğŸ  gpt-oss:20b æ¨å¥¨ã‚·ãƒŠãƒªã‚ª
- **ã‚³ã‚¹ãƒˆé‡è¦–ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ** (å®Œå…¨ç„¡æ–™)
- **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é‡è¦–** (ãƒ‡ãƒ¼ã‚¿å¤–éƒ¨é€ä¿¡ãªã—)
- **è¤‡é›‘ãªè«–ç†å‡¦ç†** (ä¸€éƒ¨ã§OpenAIè¶…ãˆ)

### æœ€çµ‚æ¨å¥¨è¨­å®š

```python
# æ¨å¥¨æ§‹æˆ (æœ€é©ãƒãƒ©ãƒ³ã‚¹)
model = "gpt-5-mini"
reasoning_effort = "low"
verbosity = "low"
# çµæœ: 3.4ç§’ã€88.9%ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æˆåŠŸç‡
```

## ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆæƒ…å ±

### å®Ÿè¡Œå¯èƒ½ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ `tests/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã•ã‚Œã¦ãŠã‚Šã€Mac Studioç’°å¢ƒã§ã‚‚åŒæ§˜ã®ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œå¯èƒ½ã§ã™ï¼š

#### 1. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ†ã‚¹ãƒˆ

```bash
# GPT-5-MINI ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
uv run tests/test_gpt5_mini_edge_cases.py

# GPT-5-MINI vs GPT-5-NANO æœ€çµ‚æ€§èƒ½æ¯”è¼ƒ
uv run tests/test_gpt5_mini_final.py

# ãƒ­ãƒ¼ã‚«ãƒ« vs OpenAI æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
uv run test_local_vs_nano_edge_cases.py
uv run test_local_vs_mini_edge_cases.py
```

#### 2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ

```bash
# reasoning_effortæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
uv run tests/performance/test_reasoning_effort.py
uv run tests/performance/test_reasoning_comparison.py

# verbosityæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ  
uv run tests/performance/test_verbosity_parameter.py

# æœ€çµ‚æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
uv run tests/performance/test_final_optimization.py
```

#### 3. å“è³ªæ¤œè¨¼ãƒ†ã‚¹ãƒˆ

```bash
# å“è³ªæ¤œè¨¼ (reasoning_effort='low')
uv run tests/performance/test_low_quality.py

# å¤‰æ•°æ“ä½œæ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ
uv run tests/performance/test_variable_correctness.py
```

### Mac Studioç’°å¢ƒã§ã®å®Ÿè¡Œæ‰‹é †

#### å‰ææ¡ä»¶
1. **Pythonç’°å¢ƒ**: Python 3.8+ ã¨ uv ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
2. **ãƒ­ãƒ¼ã‚«ãƒ«LLM**: LMStudio ã¾ãŸã¯ Ollama (gpt-oss:20b)
3. **OpenAI API**: APIí‚¤ ì„¤ì • (.openai_key ãƒ•ã‚¡ã‚¤ãƒ«)

#### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/wadayama/nlm-system.git
cd nlm-system

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv sync

# OpenAI APIã‚­ãƒ¼è¨­å®š
uv run setup_openai.py

# ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— (LMStudio)
# 1. LMStudioèµ·å‹•
# 2. gpt-oss:20b ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿  
# 3. ã‚µãƒ¼ãƒãƒ¼é–‹å§‹ (localhost:1234)
```

#### å®Ÿè¡Œä¾‹

```bash
# ç’°å¢ƒç¢ºèªãƒ†ã‚¹ãƒˆ
uv run tests/performance/test_all_models_improved.py

# ãƒ•ãƒ«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run test_local_vs_mini_edge_cases.py

# çµæœã®æ¯”è¼ƒåˆ†æ
uv run tests/test_gpt5_mini_final.py
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®è©³ç´°

### å®Ÿè£…ã•ã‚ŒãŸæœ€é©åŒ–

1. **reasoning_effort='low'**
   - å…¨ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ (OpenAI + Local)
   - å“è³ªã‚’ç¶­æŒã—ã¤ã¤å¤§å¹…é«˜é€ŸåŒ–

2. **verbosity='low'**  
   - OpenAIãƒ¢ãƒ‡ãƒ«å°‚ç”¨
   - å¿œç­”ã®ç°¡æ½”åŒ–ã«ã‚ˆã‚‹ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å‰Šæ¸›

3. **max_tokenså‰Šé™¤**
   - ä¸è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é™¤å»
   - APIäº’æ›æ€§ã®å‘ä¸Š

### æœ€é©åŒ–åŠ¹æœ

| ãƒ¢ãƒ‡ãƒ« | æœ€é©åŒ–å‰ | æœ€é©åŒ–å¾Œ | æ”¹å–„ç‡ |
|--------|----------|----------|--------|
| **gpt-5-mini** | 11.3ç§’ | **3.4ç§’** | **70.0%å‘ä¸Š** |
| **gpt-5-nano** | 11.3ç§’ | 4.1ç§’ | 63.8%å‘ä¸Š |
| **gpt-oss:20b** | ~11.0ç§’ | ~8.0ç§’ | ç´„27%å‘ä¸Š |

## ä»Šå¾Œã®è¨ˆç”»

### Mac Studioç’°å¢ƒã§ã®è¿½åŠ ãƒ†ã‚¹ãƒˆ

1. **ãƒã‚¤ã‚¨ãƒ³ãƒ‰ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ€§èƒ½è©•ä¾¡**
   - M2 Ultra/M3 Max ã§ã® gpt-oss:20b æ€§èƒ½
   - ãƒ¡ãƒ¢ãƒª32GB+ ã§ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«è©•ä¾¡

2. **è¿½åŠ ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ**
   - ã‚ˆã‚Šå¤§ããªãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ« (70B+)
   - æœ€æ–°OpenAIãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ

3. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ**
   - åŒæ™‚ã‚»ãƒƒã‚·ãƒ§ãƒ³å‡¦ç†æ€§èƒ½
   - é•·æ™‚é–“å®Ÿè¡Œå®‰å®šæ€§

### å®Ÿè¡Œäºˆå®šãƒ†ã‚¹ãƒˆ

```bash
# Mac Studioå°‚ç”¨ãƒ†ã‚¹ãƒˆ (äºˆå®š)
uv run tests/performance/test_mac_studio_performance.py
uv run tests/performance/test_large_model_comparison.py
uv run tests/performance/test_concurrent_sessions.py
```

## å‚è€ƒè³‡æ–™

- [NLMã‚·ã‚¹ãƒ†ãƒ åŸºæœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](../README.md)
- [OpenAI APIè¨­å®šã‚¬ã‚¤ãƒ‰](../GITHUB_SETUP.md)
- [ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨ˆç”»](../AGENT_ARCHITECTURE_IMPLEMENTATION_PLAN.md)

---

*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯2025å¹´8æœˆæ™‚ç‚¹ã§ã®çµæœã§ã™ã€‚å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚„ã‚·ã‚¹ãƒ†ãƒ å¤‰æ›´ã«ã‚ˆã‚ŠçµæœãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚*